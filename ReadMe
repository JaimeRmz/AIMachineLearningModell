 Machine Learning Project Descritption

Unlock the potential of data-driven insights with this Python-based machine learning project. By harnessing advanced algorithms, it delves into molecular properties to predict aqueous solubility, aiding in pharmaceutical research and development. Whether deciphering complex chemical structures or optimizing drug formulations, this model automates analysis, enabling informed decision-making. Experience the fusion of computational chemistry and predictive analytics, empowering researchers to accelerate innovation and drive impactful discoveries.



#README:

#This project involves building machine learning models to predict the aqueous solubility (logS) of chemical compounds based on their molecular properties. Here's a step-by-step guide to the project:


#We start by loading the dataset containing molecular descriptors and the corresponding solubility values.

#```python
#import pandas as pd

#df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv')
#Data Preparation
#Next, we prepare the data by separating the features (X) and the target variable (y).

#y = df['logS']
#X = df.drop('logS', axis=1)

#--Data Splitting
#We split the dataset into training and testing sets to evaluate the performance of our models.

#from sklearn.model_selection import train_test_split

#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)
#Model Building
#Linear Regression
#We begin by building a simple linear regression model.

#from sklearn.linear_model import LinearRegression

#lr = LinearRegression()
#lr.fit(X_train, y_train)
#Random Forest
#Next, we build a random forest regression model.

#from sklearn.ensemble import RandomForestRegressor

#rf = RandomForestRegressor(max_depth=2, random_state=100)
#rf.fit(X_train, y_train)
#Model Evaluation
#We evaluate the performance of both models using mean squared error (MSE) and R-squared (R2) on both training and testing datasets.

#from sklearn.metrics import mean_squared_error, r2_score

#--Evaluation for both models

#--Results DataFrame
#results = pd.DataFrame({
   # 'Method': ['Linear Regression', 'Random Forest'],
   # 'Training MSE': [lr_train_mse, rf_train_mse],
   # 'Training R2': [lr_train_r2, rf_train_r2],
   # 'Test MSE': [lr_test_mse, rf_test_mse],
   # 'Test R2': [lr_test_r2, rf_test_r2]
#})

#print(results)

#--Model Comparison
#We compare the performance of both models based on their training and testing metrics.

#df_models = pd.concat([lr_results, rf_results], axis=0).reset_index(drop=True)
#print(df_models)

#--Data Visualization of Prediction Results
#We visualize the prediction results of the linear regression model.

#import matplotlib.pyplot as plt
#import numpy as np

#plt.figure(figsize=(5,5))
#plt.scatter(x=y_train, y=y_lr_train_pred, c="#7CAE00" ,alpha=0.3)

#z = np.polyfit(y_train, y_lr_train_pred, 1)
#p = np.poly1d(z)

#plt.plot(y_train, p(y_train), '#F8766D')
#plt.ylabel('Predict LogS')
#plt.xlabel('Experimental LogS')
#plt.show()





